---
title: "Calorie Consumption During Bicycle Work: A Statistical Analysis of an Incomplete Dataset"
date: "`r format(Sys.time(), '%d %B, %Y')`"
author: Nuno Chicoria, Boris Shilov, Murat cem Kose, Yibing Liu, Robin Vermote
output: 
  bookdown::pdf_document2:
    number_sections: true
bibliography: ./bibliography.bib
---

# Introduction

This project aimed to examine data originally gathered by @macdonald1914mechanical and conveyed to us by @greenwood1918efficiency, consisting of observations on seven people performing work using a bicycle ergometer, although our current dataset appears to include extra values and data not found in @greenwood1918efficiency, though these values may indeed be present in @macdonald1914mechanical, access to which could not be obtained in a timely manner. Hitherto it shall be assumed that every row in our dataset represents a separate individual, giving a total of 24 separate individuals across 24 rows. The dataset includes three separate measurements - weight of the individuals, calories per hour spent by individuals which serves as a measure of workout intensity, and calories spent during the task.

# Methods and procedure

```{r include=FALSE, cache=FALSE}
requirements = c("nlme", "effects", "pastecs", "lattice", 
                 "psych", "ggplot2", "GGally", "mice", "VIM", "aod", "BaM", "lme4", "ipw", "gridExtra", "cowplot")
lapply(requirements, require, character.only = T)
```

## Data exploration
First we load and examine the data.
```{r echo=FALSE}
options(digits=4)
muscledata = read.table("muscle-incomplete.txt", header=T, na.strings = "NA")
muscledata
```

And the summary:

```{r echo = FALSE}
summary(muscledata)
```

Here are some descriptive statistics.

```{r figLinearRegPlots, echo=FALSE, fig.cap="\\label{fig:muscleplots}Summary plots for the dataset."}
plot(muscledata)
```

Some exploratory statistics for all individuals:

```{r figBoxPlots, echo = FALSE, fig.cap="\\label{fig:muscledataboxplots}Boxplots"}
muscledata_edit = na.omit(muscledata)
attach(muscledata)
par(mfrow=c(1,3))
stat.desc(muscledata[,c("weight","calhour","calories")],basic = TRUE, desc = TRUE)
boxplot(weight, main='weight', col="pink")
boxplot(calhour, main='calhour', col="magenta")
boxplot(calories, main='calories', col="purple")
par(mfrow=c(1,1))
```

```{r figPairsPlot, echo = FALSE, fig.cap="\\label{fig:PairsPlot}GGpairs desc"}
ggpairs(muscledata_edit)
```

Here we see that there is a strong positive correlation between calhour and calories (0.95). Whereas, a slightly positive correlation between weight and calories (0.11). 
Scatterplot with interaction and calories:

```{r figIntervsCalories, echo = FALSE, fig.cap="\\label{fig:IntervsCalories}Interaction vs calories plot"}
ggplot(muscledata_edit, aes(x=weight*calhour, y=calories))+ geom_point(colour="magenta") + geom_smooth(colour="purple", method="lm") + ggtitle("Interaction vs. calories")
```

Calculating the correlation if we exclude missing data:

```{r echo = FALSE}
cor(muscledata_edit$calhour, muscledata_edit$calories)
```

Testing the population correlationL $H_0:correlation=0$; $H1:correlation \neq 0;$ $95\%CI$.

```{r echo = FALSE}
cor.test(muscledata_edit$calhour, muscledata_edit$calories, alternative = "two.sided", method = "pearson")
```

This saying that there is no direct relation between weights and calories.

Let's try to explain heat production in function of weight and intensity of the workout, whilst allowing for interaction of the 2 predictors (whilst increasing intensity of workout, a higher weight could result in a different speed of heat production increase):
```{r figAllEffCC, echo = FALSE, fig.cap="\\label{fig:AllEffCC}All Effects plot for the complete case dataset."}
muscledata_edit = na.omit(muscledata)
muscledata.complete.case = lm(calories~weight+calhour+weight*calhour, data=muscledata_edit)
muscledata.complete.case.summary = summary(muscledata.complete.case)
muscledata.complete.case.summary
plot(allEffects(muscledata.complete.case))
```

Using the summary method, we conclude that adding weight, calhour and interaction to a model that already has the other possible components results in a significant increase in explanatory power. (note to group: was explained in last 10 slides of chapter 1, he'll probably ask about this if we don't mention it since using the anova method results in a different interpretation).

```{r echo = FALSE}
cor.test(muscledata_edit$weight, muscledata_edit$calories, alternative = "two.sided", method = "pearson")
```

## Missing data exploration

Let's explore the missingness of our data:

All missing is in calories.

```{r figMissDatBox, echo = FALSE, fig.cap="\\label{fig:MissDatBox}Pattern of missing data across variables"}
aggr(muscledata, numbers = TRUE, prop = FALSE, ylab = c("Histogram of missing data", "Pattern"), col= c("pink", "purple"))
```

In second and third we see that the missing data is distributed among weights but it is biased in calhour. The missing data  is present in the lower values of calhour. We assume that this might be because of the machine that is not efficiently working with such small heat produced by the participants.This suggests MAR as a plausible missingness mechanism. Boris explain what is MAR to the client. 

```{r figMissingHists, echo = FALSE, fig.width = 10, fig.cap="\\label{fig:MissingHists}Histograms of the observed and missing data as well as marginplots depicting histograms and correlations."}
par(mfrow=c(1,1))
histMiss(muscledata, col= c("pink", "purple"))
legend(40,8, legend=c("Observed Data", "Missing Data"),
       col=c("pink", "purple"), pch=19, cex=0.8)

histMiss(muscledata, pos=2, col= c("pink", "purple"))
legend(52,8, legend=c("Observed Data", "Missing Data"),
       col=c("pink", "purple"), pch=19, cex=0.8)

marginplot(muscledata[c("calhour","calories")], col= c("pink", "purple"))
legend(12, 345, legend=c("Observed Data", "Missing Data"),
       col=c("pink", "purple"), pch=19, cex=0.8)

marginplot(muscledata[c("weight","calories")], col= c("pink", "purple"))
legend(45, 345, legend=c("Observed Data", "Missing Data"),
       col=c("pink", "purple"), pch=19, cex=0.8)
```

## Complete case analysis

First we need to select the best linear model to use for CC - we can do this using stepwise AIC.

Using the stepwise method, we conclude that adding weight, calhour and interaction to a model that already has the other possible components results in a significant increase in explanatory power. (note to group: was explained in last 10 slides of chapter 1, he'll probably ask about this if we don't mention it since using the anova method reults in a different interpretation).


```{r echo = FALSE}
muscledata.stepwise = step(lm(calories ~1, data=muscledata_edit), scope=~weight+calhour+weight*calhour, direction="both")
```

Thus we deduce that the best-fitting model is:
$$
calories_i = \beta_0 + \beta_1*weight_i + \beta_2*calhour_i + \beta_3*(weight_i*calhour_i) + \epsilon_i
$$

The R summary for this model:

```{r echo = FALSE}
muscledata.complete.case = lm(calories~weight+calhour+weight*calhour, data=muscledata_edit)
summary(muscledata.complete.case)
```


Let's try to explain heat production in function of weight and intensity of the workout, whilst allowing for interaction of the 2 predictors (whilst increasing intensity of workout, a higher weight could result in a different speed of heat production increase):

This plot telling us that there is a decrease in coeficient between calhour and calories as calhour is increasing.

```{r figAllEffGoodModel, echo = FALSE, fig.cap="\\label{fig:AllEffGoodModel}The All Effects plot for the Complete Case linear model."}
muscledata_edit = na.omit(muscledata)
muscledata.complete.case = lm(calories~weight+calhour+weight*calhour, data=muscledata_edit)
muscledata.complete.case.summary = summary(muscledata.complete.case)
muscledata.complete.case.summary
plot(allEffects(muscledata.complete.case),main="Complete Case Effects Plot")
```


## Multiple imputation analysis

Put in a short desc of multiple imputaton here

First we use the PMM method:

```{r echo = FALSE, include=FALSE, cache=FALSE}
muscledata.imp.pmm = mice(muscledata, meth = c("", "", "pmm"), m=100) # imputation of different values, 100 different complete datasets
muscledata.fit.pmm = with(data=muscledata.imp.pmm, exp=glm(calories~weight+calhour+weight*calhour))  # analysis, creating a Q for each imputed dataset
muscledata.pmm = pool(muscledata.fit.pmm)  # pooling the Qs together to create one estimate Q mean. if Q are approx normally distributed, we calculate mean over all Q and sum the within and between imputation variance using Rubins method
summary(muscledata.pmm)
```

```{r echo = FALSE}
summary(muscledata.pmm)
```



```{r figAllEffCompPMM, echo = FALSE, fig.cap="\\label{fig:AllEffGoodModel}The All Effects plot for MI using the PMM method."}
MI.fitted.values.pmm = complete(muscledata.imp.pmm, "long", inc=T)
muscledata.results.mi.pmm = glm(calories~weight+calhour+weight*calhour, data=MI.fitted.values.pmm)
dlist=list(calhour=seq(20,60,10))
plot(allEffects(muscledata.results.mi.pmm,xlevels=dlist)[1], main="PMM Effects Plot")
```

```{r figStripCompPMM, echo = FALSE, fig.cap="\\label{fig:StripCompPMM}The strip plot of PMM data."}
col <- rep(c("pink","purple")[1+as.numeric(is.na(muscledata.imp.pmm$data$calories))],101)
stripplot(calories~.imp, data=MI.fitted.values.pmm, jit=TRUE, fac=0.8, col=col, pch=20, cex=1.4, xlab="Imputation number", main="Original data vs. generated data (PMM)")
```

What if we use the Bayesian norm method?

```{r echo = FALSE, include=FALSE, cache=FALSE}
muscledata.imp.norm = mice(muscledata, meth = c("", "", "norm"), m=100) # imputation of different values, 100 different complete datasets
muscledata.fit.norm = with(data=muscledata.imp.norm, exp=glm(calories~weight+calhour+weight*calhour))  # analysis, creating a Q for each imputed dataset
muscledata.norm = pool(muscledata.fit.norm)  # pooling the Qs together to create one estimate Q mean. if Q are approx normally distributed, we calculate mean over all Q and sum the within and between imputation variance using Rubins method
```

```{r echo = FALSE}
summary(muscledata.norm)
```


```{r figAllEffCompNORM, echo = FALSE, fig.cap="\\label{fig:AllEffCompNORM}The All Effects plot for MI using the Bayesian NORM method."}
MI.fitted.values.norm = complete(muscledata.imp.norm, "long", inc=T)
muscledata.results.mi.norm = glm(calories~weight+calhour+weight*calhour, data=MI.fitted.values.norm)
dlist=list(calhour=seq(20,60,10))
plot(allEffects(muscledata.results.mi.norm,xlevels=dlist)[1], main="NORM effects plot")
```

```{r figStripCompNORM, echo = FALSE, fig.cap="\\label{fig:StripCompNORM}The strip plot of Bayesian NORM data."}
col <- rep(c("pink","purple")[1+as.numeric(is.na(muscledata.imp.norm$data$calories))],101)
stripplot(calories~.imp, data=MI.fitted.values.norm, jit=TRUE, fac=0.8, col=col, pch=20, cex=1.4, xlab="Imputation number", main="Original data vs. generated data (NORM)")
```


## IPW analysis


```{r echo = FALSE}
IPWanal_muscledata = muscledata
IPWanal_muscledata$r = as.numeric(!is.na(IPWanal_muscledata$calories))
muscledata.ipw.glm = lm(r ~ calhour, data=IPWanal_muscledata, family=binomial)
summary(muscledata.ipw.glm)
IPWanal_muscledata$w = 1/fitted(muscledata.ipw.glm)
muscledata.results.ipw= lm(calories~weight+calhour+weight*calhour, data=IPWanal_muscledata, weights=muscledata$w)
summary(muscledata.results.ipw)
```

```{r figAllEffIPW, echo = FALSE, fig.cap="\\label{fig:AllEffIPW}The All Effects plot for our IPW-modelled data."}
plot(allEffects(muscledata.results.ipw), main="IPW effects plot")
```

We can take a look at the AIC values of the complete case and IPW models to compare:

```{r echo = FALSE}
AIC(muscledata.complete.case)
```
```{r echo = FALSE}
AIC(muscledata.results.ipw)
```
 


# Discussion

Due to the NA values, we conducted a full model analysis with a complete case and three NA comparsions (you can write this better) models. Beacuse the NA values are not evenly distrubited among calhour, we decided to try different approaches for NA handling.

PMM generates the data accordıng to the pattern ın the observed ones. ın our cases, the data ıs dıscreted by the body weıght, so pmm generated the data dıscreted as well. ın norm method, the data ıs generated based on normal dıstrıbutıon.

İn the following three graphs we can see that the behaviour of the ınteraction factor vs. calories is simillar for the cc model and the two models created under MI. This three graphs are relevant to see how the two different methods chose in MI generate the new values.

IPW assigns weights to each observation so it uses already availible ones. Since all calorıes values ın calhour 13 are  mıssıng, the method cannot assıgn a weıght. no value can represent thıs group, other mıssıng values fall ınto calhour 19, whıle a hıgher weıght ıs assıgned to the only avaılable data ın calhour 19. so the only dıfference between cc and ıpw is only based on thıs value, thus the graph is the mostly the same for both CC and IPW and that's why we chose to represent both with the same graph.

```{r figDiscInteraction, echo = FALSE, fig.width=10, fig.height=10, fig.cap="\\label{fig:DiscInteraction}Interaction scatterplots for the normal NA-excluded dataset, values fitted using NORM and values fitted using PMM."}
complete=ggplot(muscledata_edit, aes(x=weight*calhour, y=calories ))+ geom_point(colour="magenta") + geom_smooth(colour="purple", method="lm") +xlab("Interaction")
norm=ggplot(MI.fitted.values.norm, aes(x=weight*calhour, y=calories))+ geom_point(colour="magenta") + geom_smooth(colour="purple", method="lm") +xlab("Interaction")
pmm=ggplot(MI.fitted.values.pmm, aes(x=weight*calhour, y=calories))+ geom_point(colour="magenta") + geom_smooth(colour="purple", method="lm") +xlab("Interaction")
plot_grid(complete, pmm, norm , 
          labels = c("CC/IPW", "PMM", "NORM"),
          ncol = 2, nrow = 2)
```


```{r echo=FALSE}
par(mfrow=c(2,1))
col <- rep(c("pink","purple")[1+as.numeric(is.na(muscledata.imp.pmm$data$calories))],101)
stripplot(calories~.imp, data=MI.fitted.values.pmm, jit=TRUE, fac=0.8, col=col, pch=20, cex=1.4, xlab="Imputation number", main="Original data vs. generated data (PMM)")
```

```{r echo=FALSE}
col <- rep(c("pink","purple")[1+as.numeric(is.na(muscledata.imp.norm$data$calories))],101)
stripplot(calories~.imp, data=MI.fitted.values.norm, jit=TRUE, fac=0.8, col=col, pch=20, cex=1.4, xlab="Imputation number", main="Original data vs. generated data (NORM)")
```


Because there are no calorie values for calhour 13, there are no data to atributte weights to. So, IPW will make a difference only for calhour 19. This gives us a slightly better model with IPW than complete case. 

```{r figDiscCompare, echo = FALSE, fig.width=10, fig.height=10, ig.cap="\\label{fig:DiscCompate}Condensed All Effects plots from the various analysis types side by side."}

CCplot = plot(allEffects(muscledata.complete.case)[[1]], multiline=TRUE, ci.style = "bands")
NORMplot = plot(allEffects(muscledata.results.mi.norm,xlevels=dlist)[[1]], multiline=TRUE, ci.style = "bands")
PMMplot = plot(allEffects(muscledata.results.mi.pmm, xlevels=dlist)[[1]], multiline=TRUE, ci.style = "bands")
IPWplot = plot(allEffects(muscledata.results.ipw)[[1]], multiline=TRUE, ci.style = "bands")
class(CCplot) = class(NORMplot) = class(PMMplot) = class(IPWplot) = "trellis"
grid.arrange(CCplot, NORMplot, PMMplot, IPWplot, ncol=2, nrow=2)
```


# Conclusion

In our case, IPW doesn't come as an improvement in comparison to the CC model. 
and using standard error


The missing data is correlated with the calhour - intensity of the exercise - hence there is something wrong with the experimental design. Such as the way they measured heat production, so they could not accurately measure calorie burning. While we have no data for low calhour values, attributing weights to the values we have is not workable for the 13 calhour data point. That being said, the MI approach provides a more robust estimates for missing data.

# References

